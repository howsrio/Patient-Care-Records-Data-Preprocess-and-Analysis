{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa9c57f-d4f3-47bd-a7ab-3cc900fcc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 벤다이어그램용\n",
    "%matplotlib inline\n",
    "import venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5e6b0c-fa77-4962-a504-09e99361b32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "bucheon_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (29,55,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon_medical_df 로드 완료\n",
      "bucheon_vital_df 로드 완료\n",
      "bucheon_merge_df 저장완료\n",
      "bundang 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (5,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (3,10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "bundang_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (4,29,57,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bundang_medical_df 로드 완료\n",
      "bundang_vital_df 로드 완료\n",
      "bundang_merge_df 저장완료\n",
      "busan 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "busan_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "busan_medical_df 로드 완료\n",
      "busan_vital_df 로드 완료\n",
      "busan_merge_df 저장완료\n",
      "hongdae 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "hongdae_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (29,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hongdae_medical_df 로드 완료\n",
      "hongdae_vital_df 로드 완료\n",
      "hongdae_merge_df 저장완료\n",
      "jamsil 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (9,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (3,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "jamsil_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (8,29,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamsil_medical_df 로드 완료\n",
      "jamsil_vital_df 로드 완료\n",
      "jamsil_merge_df 저장완료\n",
      "gangnam 데이터 전처리 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "gangnam_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_22888\\2951950599.py:368: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gangnam_medical_df 로드 완료\n",
      "gangnam_vital_df 로드 완료\n",
      "gangnam_merge_df 저장완료\n",
      "incheon 데이터 전처리 시작\n",
      "All files are added\n",
      "이미 존재합니다.\n",
      "incheon_inbody_df 로드 완료\n",
      "incheon_medical_df 로드 완료\n",
      "incheon_vital_df 로드 완료\n",
      "incheon_merge_df 저장완료\n"
     ]
    }
   ],
   "source": [
    "region_list=[ 'bucheon', 'bundang', 'busan', 'hongdae', 'jamsil', 'gangnam','incheon']\n",
    "\n",
    "for region in region_list:\n",
    "    print(f'{region} 데이터 전처리 시작')\n",
    "    region = DataPreprocess(region = region)\n",
    "    region.dataSet()\n",
    "    region.makeDir()\n",
    "\n",
    "    region.makeVital()\n",
    "    region.makeMedical()\n",
    "    region.makeInbody()\n",
    "    region.saveDataFrame()\n",
    "\n",
    "    region.loadPreprocessData()\n",
    "    region.makeMerge()\n",
    "    region.saveMergeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d1f2d8-64a0-49d4-a33c-386b3715aa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocess:\n",
    "    \n",
    "    def __init__(self, region):\n",
    "        \n",
    "        self.path = os.getcwd()\n",
    "        self.path = os.path.dirname(self.path)\n",
    "        self.path = os.path.dirname(self.path)\n",
    "        self.path= self.path + f'\\\\region\\\\{region}' #'\\\\region\\\\{}'.format(region) \n",
    "        self.region = region\n",
    "        \n",
    "    def makeDir(self):\n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData') \n",
    "         \n",
    "        if not os.path.exists(self.newPath):\n",
    "            os.makedirs(os.path.join(f'{self.path}\\\\PreprocessData'))\n",
    "        else:\n",
    "            print('이미 존재합니다.')\n",
    "        \n",
    "        # 0_ 은 파일리스트 뽑을 때 commonPatientID 디렉토리를 맨 앞에 두기 위해서 해놓음.\n",
    "    \n",
    "    def dataSet(self):\n",
    "        #filelist 부분을 합침\n",
    "        self.fileList = os.listdir(self.path)\n",
    "        file_list = []\n",
    "        for filename in self.fileList:\n",
    "            # 파일명이 문자열을 포함하는지 확인\n",
    "            if self.region in filename:\n",
    "                file_list.append(filename)\n",
    "        self.fileList = file_list\n",
    "        self.dataDict = {}\n",
    "        for i in self.fileList:\n",
    "            self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
    "        print('All files are added')\n",
    "        return self.dataDict\n",
    "    \n",
    "    # Tmedication에는 환자정보와 시간이 없어서 만들기위해 TMedicalRecord와 MedicalRecordID를 key로서 사용하여 연결\n",
    "    def Tmedication(self):\n",
    "        \n",
    "        #2024 버전의 데이터에 맞춰 변경\n",
    "        temp = self.dataDict[f'{self.region}_tmedicalrecord.csv'][['MedicalRecordID','PatientID','ConsultTime']]\n",
    "\n",
    "        \n",
    "        #저장하는 형식으로 코드 수정\n",
    "        self.dataDict['{}_tmedication.csv'.format(self.region)] = \\\n",
    "            pd.merge(temp,self.dataDict['{}_tmedication.csv'.format(self.region)], how = 'inner', on = 'MedicalRecordID')\n",
    "\n",
    "        \n",
    "        \n",
    "    def patientChartNo(self):\n",
    "        self.dataDict[f'{self.region}_tpatientpersonal.csv'] = \\\n",
    "        self.dataDict[f'{self.region}_tpatientpersonal.csv'].loc[self.dataDict[f'{self.region}_tpatientpersonal.csv']['PatientChartNo'].notnull()]\n",
    "\n",
    "    def countUniquePatientID(self):\n",
    "        for i in self.dataDict.keys():\n",
    "            sheetPatientIDSet = self.dataDict[i]['PatientID']\n",
    "            print(f'{i} sheetPatientIDSet,{len(sheetPatientIDSet)}')\n",
    "            sheetPatientIDSet = set(self.dataDict[i]['PatientID'])\n",
    "            print(f'{i} sheetPatientIDSet,{len(sheetPatientIDSet)}')\n",
    "\n",
    "    def vennDiagram(self):\n",
    "        self.inbodySet        = set(self.dataDict['{}_tinbodyadditionaldata.csv'.format(self.region)]['PatientID'])\n",
    "        self.privateSet       = set(self.dataDict[f'{self.region}_tpatientpersonal.csv']['PatientID'])\n",
    "        self.medicationSet    = set(self.dataDict['{}_tmedication.csv'.format(self.region)]['PatientID'])\n",
    "        self.medicalRecordSet = set(self.dataDict['{}_tmedicalrecord.csv'.format(self.region)]['PatientID'])\n",
    "        self.vitalTempSet     = set(self.dataDict['{}_tpatientvitaltemp.csv'.format(self.region)]['PatientID'])\n",
    "    \n",
    "        self.labels = venn.get_labels([self.inbodySet,self.privateSet,self.medicationSet,self.medicalRecordSet,self.vitalTempSet])\n",
    "        # augument 로 fill을 안써도 되는구나 ( pilot 보면 여기에 써놓음)\n",
    "        plt.figure(figsize=(12,8))\n",
    "        fig,ax = venn.venn5(self.labels,names = ['inbody','private','medication','medicalRecord','vitalTemp'])\n",
    "        plt.title(f'{self.region}')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def makeInbody(self):\n",
    "        \n",
    "        df_path = os.path.join(f'{self.path}\\\\PreprocessData\\\\{self.region}_inbody.csv')\n",
    "        # if os.path.exists(df_path):\n",
    "        #     raise FileExistsError(f\"'inbody' 파일이 {self.region} PreprocessData 디렉토리에 이미 존재합니다.\")\n",
    "\n",
    "                \n",
    "        \n",
    "        #파일 리스트를 만들고 문제가 있는 파일 제거\n",
    "        #impedence와 measurement는 plat작업이 필요\n",
    "        #obestity는 인덱스 에러(?)\n",
    "        \n",
    "        inbody_file_names = [filename for filename in self.fileList if isinstance(filename, str) and 'inbody' in filename.lower()]\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodyimpedence.csv')\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodymeasurement.csv')\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodyobesitydiagnosis.csv')\n",
    "\n",
    "        for i, name in enumerate(inbody_file_names):\n",
    "            df = self.dataDict[name]\n",
    "            print()\n",
    "            print(i, name, len(df))\n",
    "            df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "            df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "\n",
    "            \n",
    "            if i == 0 :\n",
    "                inbody_total_df = df\n",
    "                \n",
    "            if name == f'{self.region}_tinbodychildgrowth.csv':\n",
    "                continue\n",
    "        \n",
    "            else:\n",
    "                df.drop(columns=['ReadingID'], inplace=True)\n",
    "                df_columns = set(df.columns)\n",
    "                total_columns = set(inbody_total_df.columns)\n",
    "                common_feature = list(df_columns & total_columns)\n",
    "                print(common_feature)\n",
    "                inbody_total_df =pd.merge(inbody_total_df, df, on = common_feature)\n",
    "                print(len(inbody_total_df))\n",
    "\n",
    "        self.inbody_imsi_df = inbody_total_df\n",
    "        #measurment part\n",
    "        df = self.dataDict[f'{self.region}_tinbodymeasurement.csv']\n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "        df = df.iloc[:,1:12]\n",
    "\n",
    "        #measurment feature 생성\n",
    "        feature_names = df.columns[3:]\n",
    "        neck_feature_names = ['neck_'+ name for name in feature_names]\n",
    "        chest_feature_names = ['chest_'+ name for name in feature_names]\n",
    "        abdomen_feature_names = ['abdomen_'+ name for name in feature_names]\n",
    "        hip_feature_names = ['hip_'+ name for name in feature_names]\n",
    "        Larm_feature_names = ['Larm_'+ name for name in feature_names]\n",
    "        Rarm_feature_names = ['Rarm_'+ name for name in feature_names]\n",
    "        Lleg_feature_names = ['Lleg_'+ name for name in feature_names]\n",
    "        Rleg_feature_names = ['Rleg_'+ name for name in feature_names]\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i % 8 == 0:\n",
    "                imsi_dict = {'PatientID': df.loc[0,'PatientID'], 'MeasureDate' : df.loc[0,'MeasureDate']}\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {neck_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 1:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {chest_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 2:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {abdomen_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 3:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {hip_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 4:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Larm_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 5:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Rarm_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 6:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Lleg_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 7:\n",
    "                imsi_list=list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Rleg_feature_names[i]:[imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "                \n",
    "            if i < 7:\n",
    "                continue\n",
    "            elif i == 7:\n",
    "                mesurment_df = pd.DataFrame(imsi_dict)\n",
    "            elif i % 8 == 7:\n",
    "                imsi_df = pd.DataFrame(imsi_dict)\n",
    "                mesurment_df = pd.concat([mesurment_df, imsi_df])\n",
    "            mesurment_df.reset_index(inplace=True, drop=True)\n",
    "        self.measurment_df = mesurment_df\n",
    "            \n",
    "        print(mesurment_df.shape)\n",
    "        print(mesurment_df.head())\n",
    "\n",
    "        #병합\n",
    "        inbody_total_df =pd.concat([inbody_total_df,mesurment_df.iloc[:,2:]], axis =1)\n",
    "\n",
    "        #impedence part\n",
    "        df = self.dataDict[f'{self.region}_tinbodyimpedence.csv']        \n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "\n",
    "        print(df.head())\n",
    "\n",
    "        #freq 기준으로 feature 만듬\n",
    "        feature_names = df.columns[4:9]\n",
    "        feature_names1 = ['1_'+ name for name in feature_names]\n",
    "        feature_names5 = ['5_'+ name for name in feature_names]\n",
    "        feature_names50 = ['50_'+ name for name in feature_names]\n",
    "        feature_names250 = ['250_'+ name for name in feature_names]\n",
    "        feature_names500 = ['500_'+ name for name in feature_names]\n",
    "        feature_names1000 = ['1000_'+ name for name in feature_names]\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i % 6 == 0:\n",
    "                imsi_dict = {'PatientID': df.loc[0,'PatientID'], 'MeasureDate' : df.loc[0,'MeasureDate']}\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names1[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 1:\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names5[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 2:\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names50[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 3:\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names250[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 4:\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names500[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 5:\n",
    "                imsi_list=list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names1000[i]:[imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "                \n",
    "            if i < 5:\n",
    "                continue\n",
    "            elif i == 5:\n",
    "                impedence_df = pd.DataFrame(imsi_dict)\n",
    "            elif i % 6 == 5:\n",
    "                imsi_df = pd.DataFrame(imsi_dict)\n",
    "                impedence_df = pd.concat([impedence_df, imsi_df])\n",
    "        \n",
    "\n",
    "        impedence_df.reset_index(inplace=True, drop=True)\n",
    "        inbody_total_df = pd.concat([inbody_total_df, impedence_df.iloc[:,2:]], axis = 1)\n",
    "        self.impedence_df = impedence_df\n",
    "\n",
    "        #obesitydiagnosis part\n",
    "        df = self.dataDict[f'{self.region}_tinbodyobesitydiagnosis.csv']\n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "        df.drop(columns=['ReadingID'], inplace=True)\n",
    "        df = df.drop('PSMM', axis=1)\n",
    "        df = df.drop('PWeight', axis=1)\n",
    "        df = df.drop('Weight', axis=1)\n",
    "        df = df.drop('ReadingID_ORG', axis=1)\n",
    "\n",
    "        self.obesity_df = df\n",
    "\n",
    "        inbody_total_df = pd.merge(inbody_total_df, df, on = ['MeasureDate', 'PatientID'])\n",
    "        print(inbody_total_df.shape)\n",
    "        print(inbody_total_df.head())\n",
    "\n",
    "        self.inbody_df = inbody_total_df\n",
    "        return self.inbody_df\n",
    "\n",
    "\n",
    "    def makeMedical(self):\n",
    "        df_path = os.path.join(f'{self.path}\\\\PreprocessData\\\\{self.region}_medical.csv')\n",
    "        if os.path.exists(df_path):\n",
    "            raise FileExistsError(f\"'medical' 파일이 {self.region} PreprocessData 디렉토리에 이미 존재합니다.\")\n",
    "        \n",
    "        #데이터 업로드\n",
    "        medrec_df = self.dataDict[f'{self.region}_tmedicalrecord.csv']\n",
    "        medication_df =self.dataDict[f'{self.region}_tmedication.csv']\n",
    "        #시간 조정\n",
    "        medrec_df['ConsultTime'] = pd.to_datetime(medrec_df['ConsultTime'], format='%Y%m%d%H%M%S')\n",
    "        medrec_df = medrec_df.sort_values(by=['PatientID', 'ConsultTime']).reset_index(drop=True)\n",
    "        #주요변수 리스트\n",
    "        medication_group= medication_df.groupby('MedicalRecordID')\n",
    "        MedicineName_vec = medication_group.apply(lambda x: list(x['MedicineName']))\n",
    "        code_vec = medication_group.apply(lambda x: list(x['MedicineCode']))\n",
    "        Memo_vec = medication_group.apply(lambda x: list(x['Memo']))\n",
    "        combine_df = pd.concat([MedicineName_vec,code_vec,Memo_vec], axis =1)\n",
    "        #나머지 변수 데이터프레임화\n",
    "        imsi_df = medication_group.first()\n",
    "        imsi_df.drop('MedicineCode', axis = 1, inplace = True)\n",
    "        imsi_df.drop('MedicineName', axis = 1, inplace = True)\n",
    "        imsi_df.drop('Memo', axis = 1, inplace = True)\n",
    "        #데이터 병합\n",
    "        imsi_df =pd.merge(combine_df, imsi_df, on ='MedicalRecordID')\n",
    "        imsi_df=imsi_df.reset_index() #인덱스 재설정\n",
    "        medication_df = imsi_df.rename(columns={0: 'MedicineName',1:'MedicineCode', 2:'Memo'})\n",
    "        self.medical_df = pd.merge(medrec_df, medication_df, on = 'MedicalRecordID', how= 'outer')\n",
    "\n",
    "        print(self.medical_df.shape)\n",
    "        print(self.medical_df.head())\n",
    "        \n",
    "        return self.medical_df\n",
    "\n",
    "    def makeVital(self):\n",
    "        \n",
    "        #데이터 프레임 로드및 정리\n",
    "        #vitalvalue1만 상용하고 2는 인바디 데이터로 따로 저장하지 않았음\n",
    "        #코드 3: 최고혈압, 코드 4: 최저 혈압, 코드 6: 맥박\n",
    "        vital_df = self.dataDict[f'{self.region}_tpatientvitaltemp.csv']        \n",
    "        vital_df.sort_values(by = 'PatientID')\n",
    "        vital_df['CheckDate'] = pd.to_datetime(vital_df['CheckDate'], format='%Y%m%d%H%M%S')\n",
    "        vital_df['CrTime'] = pd.to_datetime(vital_df['CrTime'], format='%Y%m%d%H%M%S')\n",
    "        vital_df.drop('VitalValue2',axis =1, inplace = True)\n",
    "        vital_df.drop('VitalID_ORG',axis =1, inplace = True)\n",
    "        vital_df.drop('VitalID',axis =1, inplace = True)\n",
    "\n",
    "        MaxVital_df = vital_df[vital_df['Code']==3]\n",
    "        MinVital_df = vital_df[vital_df['Code']==4]\n",
    "        Pulse_df = vital_df[vital_df['Code']==6]  #분당점만 14 !!!\n",
    "        MaxVital_df.drop('Code', axis =1, inplace = True)\n",
    "        MaxVital_df['MaxVital']= MaxVital_df['VitalValue']\n",
    "        MaxVital_df.drop('VitalValue', axis =1, inplace = True)\n",
    "        MinVital_df.drop('Code', axis = 1, inplace =True)\n",
    "        Pulse_df.drop('Code', axis = 1, inplace =True)\n",
    "        MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
    "        Pulse_df['Pulse'] = Pulse_df['VitalValue']\n",
    "        MinVital_df.drop('VitalValue', axis = 1, inplace =True)\n",
    "        Pulse_df.drop('VitalValue', axis = 1, inplace =True)\n",
    "\n",
    "        imsi_df = pd.merge(MaxVital_df, MinVital_df, on = ['PatientID', 'CheckDate', 'CrTime'])\n",
    "        imsi_df = pd.merge(imsi_df, Pulse_df, on = ['PatientID', 'CheckDate', 'CrTime'])\n",
    "\n",
    "        self.vital_df = imsi_df\n",
    "        \n",
    "        return self.vital_df\n",
    "\n",
    "\n",
    "\n",
    "    def saveDataFrame(self):            \n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "        \n",
    "        #inbody\n",
    "        self.inbody_df.to_csv(f'{self.newPath}\\\\{self.region}_inbody.csv', index=False)\n",
    "        self.inbody_df.to_excel(f'{self.newPath}\\\\{self.region}_inbody.xlsx', index=False)\n",
    "        print(f'{self.region}_inbody_df 저장완료')\n",
    "        \n",
    "        #medical\n",
    "        self.medical_df.to_csv(f'{self.newPath}\\\\{self.region}_medical.csv', index=False)\n",
    "        self.medical_df.to_excel(f'{self.newPath}\\\\{self.region}_medical.xlsx', index=False)\n",
    "        print(f'{self.region}_medical_df 저장완료')\n",
    "        \n",
    "        #vital    \n",
    "        self.vital_df.to_csv(f'{self.newPath}\\\\{self.region}_vital.csv', index=False)\n",
    "        self.vital_df.to_excel(f'{self.newPath}\\\\{self.region}_vital.xlsx', index=False)\n",
    "        print(f'{self.region}_vital_df 저장완료')\n",
    "\n",
    "    def saveMergeData(self):\n",
    "        #merge\n",
    "        self.merge_df.to_csv(f'{self.newPath}\\\\{self.region}_merge.csv', index=False)\n",
    "        self.merge_df.to_excel(f'{self.newPath}\\\\{self.region}_merge.xlsx', index=False)\n",
    "        print(f'{self.region}_merge_df 저장완료')\n",
    "        \n",
    "\n",
    "    def loadPreprocessData(self):\n",
    "        \n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "        try:\n",
    "            self.inbody_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_inbody.csv')\n",
    "            print(f\"{self.region}_inbody_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_inbody_df 로드 실패\")\n",
    "            pass \n",
    "            \n",
    "        try:\n",
    "            self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n",
    "            print(f\"{self.region}_medical_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_medical_df 로드 실패\")\n",
    "            pass \n",
    "            \n",
    "        try:\n",
    "            self.vital_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_vital.csv')\n",
    "            print(f\"{self.region}_vital_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_vital_df 로드 실패\")\n",
    "            pass \n",
    "\n",
    "        # try:\n",
    "        #     self.merge_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_merge.csv')\n",
    "        #     print(f\"{self.region}_merge_df 로드 완료\")\n",
    "        # except Exception as e:\n",
    "        #     # 에러 발생 시 실행할 코드 작성\n",
    "        #     print(f\"{self.region}_merge_df 로드 실패\")\n",
    "        #     pass \n",
    "            \n",
    "    def makeMerge(self):\n",
    "\n",
    "        \n",
    "        #데이터 로드\n",
    "        #저장된 파일을 로드하지 않으면 timestamp error가 발생생\n",
    "        inbody_df = self.inbody_df\n",
    "        medical_df = self.medical_df\n",
    "        vital_df = self.vital_df\n",
    "\n",
    "        #전처리\n",
    "        medical_df.drop('CrTime',axis =1, inplace =True)\n",
    "        medical_df.drop('Weight',axis =1, inplace =True)\n",
    "        medical_df['Date'] = medical_df['ConsultTime'].apply(lambda x: x.split()[0])\n",
    "        inbody_df['Date'] = inbody_df['MeasureDate'].apply(lambda x: x.split()[0])\n",
    "        vital_df['Date'] = vital_df['CheckDate'].apply(lambda x: x.split()[0])\n",
    "        merge_df = pd.merge(medical_df, inbody_df, on=['PatientID', 'Date'], how = 'outer')\n",
    "        merge_df = pd.merge(merge_df, vital_df, on=['PatientID', 'Date'], how = 'outer')\n",
    "        \n",
    "\n",
    "        #반복측정 제거 과정\n",
    "        df_unique = merge_df.drop_duplicates(subset=['PatientID', 'Date'], keep='first')\n",
    "        self.merge_df = df_unique\n",
    "\n",
    "        return self.merge_df\n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad876d5-96ce-4d81-ae3b-10a62a8992cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (5,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (3,10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n",
      "bundang_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:364: DtypeWarning: Columns (4,29,57,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bundang_medical_df 로드 완료\n",
      "bundang_vital_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('Code', axis =1, inplace = True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:310: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df['MaxVital']= MaxVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('VitalValue', axis =1, inplace = True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:312: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('Code', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:313: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('Code', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:314: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:316: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('VitalValue', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('VitalValue', axis = 1, inplace =True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bundang_inbody_df 저장완료\n",
      "bundang_medical_df 저장완료\n",
      "bundang_vital_df 저장완료\n"
     ]
    }
   ],
   "source": [
    "bundang = DataPreprocess(region = 'bundang')\n",
    "bundang.dataSet()\n",
    "bundang.makeDir()\n",
    "bundang.loadPreprocessData()\n",
    "# bundang.makeMerge()\n",
    "bundang.makeVital()\n",
    "# # bundang.makeMedical()\n",
    "# # bundang.makeInbody()\n",
    "bundang.saveDataFrame()\n",
    "# # bundang.loadPreprocessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e96c98cf-4324-4fd9-a392-7d6c86e52bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (5,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (3,10,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:32: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path+'\\\\{}'.format(i), encoding = 'utf-16', index_col = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bundang\u001b[38;5;241m.\u001b[39mdataSet()\n\u001b[1;32m----> 2\u001b[0m bundang\u001b[38;5;241m.\u001b[39mdataDict()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "bundang.dataSet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d855c963-71e2-4b8c-a711-92496733fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VitalID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>CheckDate</th>\n",
       "      <th>Code</th>\n",
       "      <th>VitalValue</th>\n",
       "      <th>CrTime</th>\n",
       "      <th>VitalValue2</th>\n",
       "      <th>VitalID_ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6589186</td>\n",
       "      <td>390190</td>\n",
       "      <td>202211070310</td>\n",
       "      <td>3.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>20221107091521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6589191</td>\n",
       "      <td>390190</td>\n",
       "      <td>202211070310</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20221107091521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6589196</td>\n",
       "      <td>390190</td>\n",
       "      <td>202211070310</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20221107091521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6589201</td>\n",
       "      <td>390190</td>\n",
       "      <td>202211070310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20221107091521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6589206</td>\n",
       "      <td>390190</td>\n",
       "      <td>202211070310</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20221107091521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160757</th>\n",
       "      <td>7387631</td>\n",
       "      <td>480101</td>\n",
       "      <td>202405140930</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20240514193152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160758</th>\n",
       "      <td>7387636</td>\n",
       "      <td>480101</td>\n",
       "      <td>202405140930</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20240514193152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160759</th>\n",
       "      <td>7387641</td>\n",
       "      <td>480101</td>\n",
       "      <td>202405140930</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20240514193152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160760</th>\n",
       "      <td>7387646</td>\n",
       "      <td>480101</td>\n",
       "      <td>202405140930</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20240514193152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160761</th>\n",
       "      <td>7387651</td>\n",
       "      <td>480101</td>\n",
       "      <td>202405141930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20240514193245</td>\n",
       "      <td>1:166.0|2:65.7|5:23.8|6:0.381|7:0.381|8:0.381|...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160762 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VitalID  PatientID     CheckDate  Code  VitalValue          CrTime  \\\n",
       "0       6589186     390190  202211070310   3.0       148.0  20221107091521   \n",
       "1       6589191     390190  202211070310   4.0        88.0  20221107091521   \n",
       "2       6589196     390190  202211070310  14.0        70.0  20221107091521   \n",
       "3       6589201     390190  202211070310   1.0         0.0  20221107091521   \n",
       "4       6589206     390190  202211070310   2.0         0.0  20221107091521   \n",
       "...         ...        ...           ...   ...         ...             ...   \n",
       "160757  7387631     480101  202405140930  12.0         0.0  20240514193152   \n",
       "160758  7387636     480101  202405140930   5.0         0.0  20240514193152   \n",
       "160759  7387641     480101  202405140930   9.0         0.0  20240514193152   \n",
       "160760  7387646     480101  202405140930  15.0         0.0  20240514193152   \n",
       "160761  7387651     480101  202405141930   NaN         0.0  20240514193245   \n",
       "\n",
       "                                              VitalValue2  VitalID_ORG  \n",
       "0                                                     NaN          NaN  \n",
       "1                                                     NaN          NaN  \n",
       "2                                                     NaN          NaN  \n",
       "3                                                     NaN          NaN  \n",
       "4                                                     NaN          NaN  \n",
       "...                                                   ...          ...  \n",
       "160757                                                NaN          NaN  \n",
       "160758                                                NaN          NaN  \n",
       "160759                                                NaN          NaN  \n",
       "160760                                                NaN          NaN  \n",
       "160761  1:166.0|2:65.7|5:23.8|6:0.381|7:0.381|8:0.381|...          NaN  \n",
       "\n",
       "[160762 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundang.dataDict['bundang_tpatientvitaltemp.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50e097a7-8ac3-4bbf-b8f0-c5928cdd18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('Code', axis =1, inplace = True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df['MaxVital']= MaxVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('VitalValue', axis =1, inplace = True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('Code', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('Code', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df['Pulse'] = Pulse_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('VitalValue', axis = 1, inplace =True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\2956494492.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('VitalValue', axis = 1, inplace =True)\n"
     ]
    }
   ],
   "source": [
    "# vital_df = bundang.dataDict['bundang_tpatientvitaltemp.csv']     \n",
    "# vital_df.sort_values(by = 'PatientID')\n",
    "# vital_df['CheckDate'] = pd.to_datetime(vital_df['CheckDate'], format='%Y%m%d%H%M%S')\n",
    "# vital_df['CrTime'] = pd.to_datetime(vital_df['CrTime'], format='%Y%m%d%H%M%S')\n",
    "# vital_df.drop('VitalValue2',axis =1, inplace = True)\n",
    "# vital_df.drop('VitalID_ORG',axis =1, inplace = True)\n",
    "# vital_df.drop('VitalID',axis =1, inplace = True)\n",
    "\n",
    "MaxVital_df = vital_df[vital_df['Code']==3]\n",
    "MinVital_df = vital_df[vital_df['Code']==4]\n",
    "Pulse_df = vital_df[vital_df['Code']==14]\n",
    "MaxVital_df.drop('Code', axis =1, inplace = True)\n",
    "MaxVital_df['MaxVital']= MaxVital_df['VitalValue']\n",
    "MaxVital_df.drop('VitalValue', axis =1, inplace = True)\n",
    "MinVital_df.drop('Code', axis = 1, inplace =True)\n",
    "Pulse_df.drop('Code', axis = 1, inplace =True)\n",
    "MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
    "Pulse_df['Pulse'] = Pulse_df['VitalValue']\n",
    "MinVital_df.drop('VitalValue', axis = 1, inplace =True)\n",
    "Pulse_df.drop('VitalValue', axis = 1, inplace =True)\n",
    "\n",
    "imsi_df = pd.merge(MaxVital_df, MinVital_df, on = ['PatientID', 'CheckDate', 'CrTime'])\n",
    "imsi_df = pd.merge(imsi_df, Pulse_df, on = ['PatientID', 'CheckDate', 'CrTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a4a8b02-a74e-4daf-aefc-603a7483f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsi_df.to_csv(f'{bundang.newPath}\\\\{bundang.region}_vital.csv', index=False)\n",
    "imsi_df.to_excel(f'{bundang.newPath}\\\\{bundang.region}_xlsx.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa58d4c0-6ecb-4030-9b02-0c50784fad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bundang_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_21464\\510792590.py:364: DtypeWarning: Columns (4,29,57,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bundang_medical_df 로드 완료\n",
      "bundang_vital_df 로드 완료\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\howsr\\\\workspace\\\\1_DataPreprocessing\\\\basis\\\\region\\\\bundang\\\\PreprocessData\\\\bundang_merge.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m bundang\u001b[38;5;241m.\u001b[39mloadPreprocessData()\n\u001b[0;32m      2\u001b[0m bundang\u001b[38;5;241m.\u001b[39mmakeMerge()\n\u001b[1;32m----> 3\u001b[0m bundang\u001b[38;5;241m.\u001b[39msaveMergeData()\n",
      "Cell \u001b[1;32mIn[3], line 348\u001b[0m, in \u001b[0;36mDataPreprocess.saveMergeData\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msaveMergeData\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m#merge\u001b[39;00m\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merge.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merge.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merge_df 저장완료\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2345\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2332\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2334\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2335\u001b[0m     df,\n\u001b[0;32m   2336\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2343\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2344\u001b[0m )\n\u001b[1;32m-> 2345\u001b[0m formatter\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m   2346\u001b[0m     excel_writer,\n\u001b[0;32m   2347\u001b[0m     sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   2348\u001b[0m     startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[0;32m   2349\u001b[0m     startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[0;32m   2350\u001b[0m     freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[0;32m   2351\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2352\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2353\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   2354\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:946\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    942\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(  \u001b[38;5;66;03m# type: ignore[abstract]\u001b[39;00m\n\u001b[0;32m    947\u001b[0m         writer,\n\u001b[0;32m    948\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    949\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    950\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    951\u001b[0m     )\n\u001b[0;32m    952\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m     path,\n\u001b[0;32m     63\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m     64\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m     65\u001b[0m     if_sheet_exists\u001b[38;5;241m=\u001b[39mif_sheet_exists,\n\u001b[0;32m     66\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1263\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1260\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1261\u001b[0m )\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1264\u001b[0m         path, mode, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\howsr\\\\workspace\\\\1_DataPreprocessing\\\\basis\\\\region\\\\bundang\\\\PreprocessData\\\\bundang_merge.xlsx'"
     ]
    }
   ],
   "source": [
    "bundang.loadPreprocessData()\n",
    "bundang.makeMerge()\n",
    "bundang.saveMergeData()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
