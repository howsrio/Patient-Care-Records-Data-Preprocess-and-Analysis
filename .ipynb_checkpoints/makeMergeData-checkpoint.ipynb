{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1d34f04-9a99-4b2e-a245-2c432f516633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from DataPreprocess import DataPreprocess\n",
    "\n",
    "# 벤다이어그램용\n",
    "%matplotlib inline\n",
    "import venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ba446-f3df-4dab-bb80-5e7977582691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "class DataPreprocess:\n",
    "    def __init__(self, region):\n",
    "        self.path = os.getcwd()[:-5] + f'\\\\region\\\\{region}'  # '\\\\region\\\\{}'.format(region)\n",
    "        self.region = region\n",
    "\n",
    "    def makeDir(self):\n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "\n",
    "        if not os.path.exists(self.newPath):\n",
    "            os.makedirs(os.path.join(f'{self.path}\\\\PreprocessData'))\n",
    "        else:\n",
    "            print('이미 존재합니다.')\n",
    "\n",
    "    def delDir(self):\n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "        # 'PreprocessData' 폴더가 존재하는지 확인하고 삭제\n",
    "        if os.path.exists(self.newPath) and os.path.isdir(self.newPath):\n",
    "            try:\n",
    "                shutil.rmtree(self.newPath)\n",
    "                print(f\"'{self.newPath}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "            except Exception as e:\n",
    "                print(f\"폴더를 삭제하는 중 오류가 발생했습니다: {e}\")\n",
    "        else:\n",
    "            print(f\"'{self.newPath}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "    def dataSet(self):\n",
    "        # filelist 부분을 합침\n",
    "        self.fileList = os.listdir(self.path)\n",
    "        file_list = []\n",
    "        for filename in self.fileList:\n",
    "            # 파일명이 문자열을 포함하는지 확인\n",
    "            if self.region in filename:\n",
    "                file_list.append(filename)\n",
    "        self.fileList = file_list\n",
    "        self.dataDict = {}\n",
    "        for i in self.fileList:\n",
    "            self.dataDict[i] = pd.read_csv(self.path + '\\\\{}'.format(i), encoding='utf-16', index_col=0)\n",
    "        print('All files are added')\n",
    "        return self.dataDict\n",
    "\n",
    "    # Tmedication에는 환자정보와 시간이 없어서 만들기위해 TMedicalRecord와 MedicalRecordID를 key로서 사용하여 연결\n",
    "    def Tmedication(self):\n",
    "\n",
    "        # 2024 버전의 데이터에 맞춰 변경\n",
    "        temp = self.dataDict[f'{self.region}_tmedicalrecord.csv'][['MedicalRecordID', 'PatientID', 'ConsultTime']]\n",
    "\n",
    "        # 저장하는 형식으로 코드 수정\n",
    "        self.dataDict['{}_tmedication.csv'.format(self.region)] = \\\n",
    "            pd.merge(temp, self.dataDict['{}_tmedication.csv'.format(self.region)], how='inner', on='MedicalRecordID')\n",
    "\n",
    "    def patientChartNo(self):\n",
    "        self.dataDict[f'{self.region}_tpatientpersonal.csv'] = \\\n",
    "            self.dataDict[f'{self.region}_tpatientpersonal.csv'].loc[\n",
    "                self.dataDict[f'{self.region}_tpatientpersonal.csv']['PatientChartNo'].notnull()]\n",
    "\n",
    "    def countUniquePatientID(self):\n",
    "        for i in self.dataDict.keys():\n",
    "            sheetPatientIDSet = self.dataDict[i]['PatientID']\n",
    "            print(f'{i} sheetPatientIDSet,{len(sheetPatientIDSet)}')\n",
    "            sheetPatientIDSet = set(self.dataDict[i]['PatientID'])\n",
    "            print(f'{i} sheetPatientIDSet,{len(sheetPatientIDSet)}')\n",
    "\n",
    "\n",
    "    def makeInbody(self):\n",
    "\n",
    "        # 파일 리스트를 만들고 문제가 있는 파일 제거\n",
    "        # impedence와 measurement는 plat작업이 필요\n",
    "        # obestity는 인덱스 에러(?)\n",
    "\n",
    "        inbody_file_names = [filename for filename in self.fileList if\n",
    "                             isinstance(filename, str) and 'inbody' in filename.lower()]\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodyimpedence.csv')\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodymeasurement.csv')\n",
    "        inbody_file_names.remove(f'{self.region}_tinbodyobesitydiagnosis.csv')\n",
    "\n",
    "        for i, name in enumerate(inbody_file_names):\n",
    "            df = self.dataDict[name]\n",
    "            # print()\n",
    "            # print(i, name, len(df))\n",
    "            df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "            df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "    \n",
    "            if name == f'{self.region}_tinbodychildgrowth.csv':\n",
    "                continue\n",
    "            \n",
    "            if i == 0:\n",
    "                inbody_total_df = df\n",
    "\n",
    "            else:\n",
    "                df.drop(columns=['ReadingID'], inplace=True)\n",
    "                df_columns = set(df.columns)\n",
    "                total_columns = set(inbody_total_df.columns)\n",
    "                common_feature = list(df_columns & total_columns)\n",
    "                # print(common_feature)\n",
    "                inbody_total_df = pd.merge(inbody_total_df, df, on=common_feature)\n",
    "                # print(len(inbody_total_df))\n",
    "\n",
    "        # measurment part\n",
    "        df = self.dataDict[f'{self.region}_tinbodymeasurement.csv']\n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "        df = df.iloc[:, 1:12]\n",
    "\n",
    "        # measurment feature 생성\n",
    "        feature_names = df.columns[3:]\n",
    "        neck_feature_names = ['neck_' + name for name in feature_names]\n",
    "        chest_feature_names = ['chest_' + name for name in feature_names]\n",
    "        abdomen_feature_names = ['abdomen_' + name for name in feature_names]\n",
    "        hip_feature_names = ['hip_' + name for name in feature_names]\n",
    "        Larm_feature_names = ['Larm_' + name for name in feature_names]\n",
    "        Rarm_feature_names = ['Rarm_' + name for name in feature_names]\n",
    "        Lleg_feature_names = ['Lleg_' + name for name in feature_names]\n",
    "        Rleg_feature_names = ['Rleg_' + name for name in feature_names]\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i % 8 == 0:\n",
    "                imsi_dict = {'PatientID': df.loc[0, 'PatientID'], 'MeasureDate': df.loc[0, 'MeasureDate']}\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {neck_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 1:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {chest_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 2:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {abdomen_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 3:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {hip_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 4:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Larm_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 5:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Rarm_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 6:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Lleg_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 8 == 7:\n",
    "                imsi_list = list(df.loc[i][3:])\n",
    "                imsi_dict2 = {Rleg_feature_names[i]: [imsi_list[i]] for i in range(8)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "\n",
    "            if i < 7:\n",
    "                continue\n",
    "            elif i == 7:\n",
    "                mesurment_df = pd.DataFrame(imsi_dict)\n",
    "            elif i % 8 == 7:\n",
    "                imsi_df = pd.DataFrame(imsi_dict)\n",
    "                mesurment_df = pd.concat([mesurment_df, imsi_df])\n",
    "            mesurment_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # print(mesurment_df.shape)\n",
    "        # print(mesurment_df.head())\n",
    "\n",
    "        # 병합\n",
    "        inbody_total_df = pd.concat([inbody_total_df, mesurment_df.iloc[:, 2:]], axis=1)\n",
    "\n",
    "        # impedence part\n",
    "        df = self.dataDict[f'{self.region}_tinbodyimpedence.csv']\n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "\n",
    "        # freq 기준으로 feature 만듬\n",
    "        feature_names = df.columns[4:9]\n",
    "        feature_names1 = ['1_' + name for name in feature_names]\n",
    "        feature_names5 = ['5_' + name for name in feature_names]\n",
    "        feature_names50 = ['50_' + name for name in feature_names]\n",
    "        feature_names250 = ['250_' + name for name in feature_names]\n",
    "        feature_names500 = ['500_' + name for name in feature_names]\n",
    "        feature_names1000 = ['1000_' + name for name in feature_names]\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i % 6 == 0:\n",
    "                imsi_dict = {'PatientID': df.loc[0, 'PatientID'], 'MeasureDate': df.loc[0, 'MeasureDate']}\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names1[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 1:\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names5[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 2:\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names50[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 3:\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names250[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 4:\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names500[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "            elif i % 6 == 5:\n",
    "                imsi_list = list(df.loc[i][4:9])\n",
    "                imsi_dict2 = {feature_names1000[i]: [imsi_list[i]] for i in range(5)}\n",
    "                imsi_dict.update(imsi_dict2)\n",
    "\n",
    "            if i < 5:\n",
    "                continue\n",
    "            elif i == 5:\n",
    "                impedence_df = pd.DataFrame(imsi_dict)\n",
    "            elif i % 6 == 5:\n",
    "                imsi_df = pd.DataFrame(imsi_dict)\n",
    "                impedence_df = pd.concat([impedence_df, imsi_df])\n",
    "\n",
    "        impedence_df.reset_index(inplace=True, drop=True)\n",
    "        # print(impedence_df.shape)\n",
    "        # print(impedence_df.head())\n",
    "        inbody_total_df = pd.concat([inbody_total_df, impedence_df.iloc[:, 2:]], axis=1)\n",
    "\n",
    "        # obesitydiagnosis part\n",
    "        df = self.dataDict[f'{self.region}_tinbodyobesitydiagnosis.csv']\n",
    "        df['MeasureDate'] = pd.to_datetime(df['MeasureDate'], format='%Y%m%d%H%M%S')\n",
    "        df = df.sort_values(by=['PatientID', 'MeasureDate']).reset_index(drop=True)\n",
    "        df.drop(columns=['ReadingID'], inplace=True)\n",
    "        df = df.drop('PSMM', axis=1)\n",
    "        df = df.drop('PWeight', axis=1)\n",
    "        df = df.drop('Weight', axis=1)\n",
    "        df = df.drop('ReadingID_ORG', axis=1)\n",
    "\n",
    "        inbody_total_df = pd.merge(inbody_total_df, df, on=['MeasureDate', 'PatientID'])\n",
    "        # print(inbody_total_df.shape)\n",
    "        # print(inbody_total_df.head())\n",
    "        \n",
    "        self.inbody_df = inbody_total_df[inbody_total_df['PatientID'] != 0]\n",
    "        print(f'{len(inbody_total_df)} -> {self.inbody_df}')\n",
    "        print(f'inbody_df 완료: {inbody_df.shape}}')\n",
    "        \n",
    "        return self.inbody_df\n",
    "\n",
    "    def makeMedical(self):\n",
    "\n",
    "        # 데이터 업로드\n",
    "        medrec_df = self.dataDict[f'{self.region}_tmedicalrecord.csv']\n",
    "        medication_df = self.dataDict[f'{self.region}_tmedication.csv']\n",
    "        # 시간 조정\n",
    "        medrec_df['ConsultTime'] = pd.to_datetime(medrec_df['ConsultTime'], format='%Y%m%d%H%M%S')\n",
    "        medrec_df = medrec_df.sort_values(by=['PatientID', 'ConsultTime']).reset_index(drop=True)\n",
    "        # 주요변수 리스트\n",
    "        medication_group = medication_df.groupby('MedicalRecordID')\n",
    "        MedicineName_vec = medication_group.apply(lambda x: list(x['MedicineName']))\n",
    "        code_vec = medication_group.apply(lambda x: list(x['MedicineCode']))\n",
    "        Memo_vec = medication_group.apply(lambda x: list(x['Memo']))\n",
    "        combine_df = pd.concat([MedicineName_vec, code_vec, Memo_vec], axis=1)\n",
    "        # 나머지 변수 데이터프레임화\n",
    "        imsi_df = medication_group.first()\n",
    "        imsi_df.drop('MedicineCode', axis=1, inplace=True)\n",
    "        imsi_df.drop('MedicineName', axis=1, inplace=True)\n",
    "        imsi_df.drop('Memo', axis=1, inplace=True)\n",
    "        # 데이터 병합\n",
    "        imsi_df = pd.merge(combine_df, imsi_df, on='MedicalRecordID')\n",
    "        imsi_df = imsi_df.reset_index()  # 인덱스 재설정\n",
    "        medication_df = imsi_df.rename(columns={0: 'MedicineName', 1: 'MedicineCode', 2: 'Memo'})\n",
    "        self.medical_df = pd.merge(medrec_df, medication_df, on='MedicalRecordID', how='outer')\n",
    "\n",
    "        print(f'medical_df 완료: {self.medical_df.shape}')\n",
    "        #print(self.medical_df.head())\n",
    "\n",
    "        return self.medical_df\n",
    "\n",
    "    def makeVital(self):\n",
    "\n",
    "        # 데이터 프레임 로드및 정리\n",
    "        # vitalvalue1만 상용하고 2는 인바디 데이터로 따로 저장하지 않았음\n",
    "        # 코드 3: 최고혈압, 코드 4: 최저 혈압, 코드 6: 맥박\n",
    "        vital_df = self.dataDict[f'{self.region}_tpatientvitaltemp.csv']\n",
    "        vital_df.sort_values(by='PatientID')\n",
    "        vital_df['CheckDate'] = pd.to_datetime(vital_df['CheckDate'], format='%Y%m%d%H%M%S')\n",
    "        vital_df['CrTime'] = pd.to_datetime(vital_df['CrTime'], format='%Y%m%d%H%M%S')\n",
    "        vital_df.drop('VitalValue2', axis=1, inplace=True)\n",
    "        vital_df.drop('VitalID_ORG', axis=1, inplace=True)\n",
    "        vital_df.drop('VitalID', axis=1, inplace=True)\n",
    "\n",
    "        MaxVital_df = vital_df[vital_df['Code'] == 3]\n",
    "        MinVital_df = vital_df[vital_df['Code'] == 4]\n",
    "        Pulse_df = vital_df[vital_df['Code'] == 6]\n",
    "        MaxVital_df.drop('Code', axis=1, inplace=True)\n",
    "        MaxVital_df['MaxVital'] = MaxVital_df['VitalValue']\n",
    "        MaxVital_df.drop('VitalValue', axis=1, inplace=True)\n",
    "        MinVital_df.drop('Code', axis=1, inplace=True)\n",
    "        Pulse_df.drop('Code', axis=1, inplace=True)\n",
    "        MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
    "        Pulse_df['Pulse'] = Pulse_df['VitalValue']\n",
    "        MinVital_df.drop('VitalValue', axis=1, inplace=True)\n",
    "        Pulse_df.drop('VitalValue', axis=1, inplace=True)\n",
    "\n",
    "        imsi_df = pd.merge(MaxVital_df, MinVital_df, on=['PatientID', 'CheckDate', 'CrTime'])\n",
    "        imsi_df = pd.merge(imsi_df, Pulse_df, on=['PatientID', 'CheckDate', 'CrTime'])\n",
    "\n",
    "        self.vital_df = imsi_df\n",
    "        print(f'vital_df 완료:{vital_df.shape}')\n",
    "        \n",
    "        return self.vital_df\n",
    "\n",
    "    def saveDataFrame(self):\n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "\n",
    "        # inbody\n",
    "        self.inbody_df.to_csv(f'{self.newPath}\\\\{self.region}_inbody.csv', index=False)\n",
    "        self.inbody_df.to_excel(f'{self.newPath}\\\\{self.region}_inbody.xlsx', index=False)\n",
    "        print(f'{self.region}_inbody_df 저장완료')\n",
    "\n",
    "        # medical\n",
    "        self.medical_df.to_csv(f'{self.newPath}\\\\{self.region}_medical.csv', index=False)\n",
    "        self.medical_df.to_excel(f'{self.newPath}\\\\{self.region}_medical.xlsx', index=False)\n",
    "        print(f'{self.region}_medical_df 저장완료')\n",
    "\n",
    "        # vital\n",
    "        self.vital_df.to_csv(f'{self.newPath}\\\\{self.region}_vital.csv', index=False)\n",
    "        self.vital_df.to_excel(f'{self.newPath}\\\\{self.region}_vital.xlsx', index=False)\n",
    "        print(f'{self.region}_vital_df 저장완료')\n",
    "\n",
    "    def saveMergeData(self):\n",
    "        # merge\n",
    "        self.merge_df.to_csv(f'{self.newPath}\\\\{self.region}_merge.csv', index=False)\n",
    "        self.merge_df.to_excel(f'{self.newPath}\\\\{self.region}_merge.xlsx', index=False)\n",
    "        print(f'{self.region}_merge_df 저장완료')\n",
    "\n",
    "    def loadPreprocessData(self):\n",
    "\n",
    "        self.newPath = os.path.join(f'{self.path}\\\\PreprocessData')\n",
    "        try:\n",
    "            self.inbody_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_inbody.csv')\n",
    "            print(f\"{self.region}_inbody_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_inbody_df 로드 실패\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n",
    "            print(f\"{self.region}_medical_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_medical_df 로드 실패\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.vital_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_vital.csv')\n",
    "            print(f\"{self.region}_vital_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_vital_df 로드 실패\")\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            self.merge_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_merge.csv')\n",
    "            print(f\"{self.region}_merge_df 로드 완료\")\n",
    "        except Exception as e:\n",
    "            # 에러 발생 시 실행할 코드 작성\n",
    "            print(f\"{self.region}_merge_df 로드 실패\")\n",
    "            pass\n",
    "\n",
    "    def makeMerge(self):\n",
    "\n",
    "        # 데이터 로드\n",
    "        # 저장된 파일을 로드하지 않으면 timestamp error가 발생생\n",
    "        inbody_df = self.inbody_df\n",
    "        medical_df = self.medical_df\n",
    "        vital_df = self.vital_df\n",
    "\n",
    "        # 전처리\n",
    "        medical_df.drop('CrTime', axis=1, inplace=True)\n",
    "        medical_df.drop('Weight', axis=1, inplace=True)\n",
    "        medical_df['Date'] = medical_df['ConsultTime'].apply(lambda x: x.split()[0])\n",
    "        inbody_df['Date'] = inbody_df['MeasureDate'].apply(lambda x: x.split()[0])\n",
    "        vital_df['Date'] = vital_df['CheckDate'].apply(lambda x: x.split()[0])\n",
    "        merge_df = pd.merge(medical_df, inbody_df, on=['PatientID', 'Date'], how='outer')\n",
    "        merge_df = pd.merge(merge_df, vital_df, on=['PatientID', 'Date'], how='outer')\n",
    "\n",
    "        # 반복측정 제거 과\n",
    "        group_df = merge_df.groupby(['PatientID', 'Date'])\n",
    "        group_size = merge_df.groupby(['PatientID', 'Date']).size()\n",
    "        overlab_list = group_size[group_size != 1].index.tolist()\n",
    "\n",
    "        copy_df = merge_df.copy()\n",
    "\n",
    "        for ID, Date in overlab_list:\n",
    "            imsi_df = merge_df[merge_df['PatientID'] == ID][merge_df['Date'] == Date]\n",
    "            remove_date_list = list(imsi_df['MeasureDate'])\n",
    "            max_index = imsi_df['MeasureDate'].max()\n",
    "            remove_date_list.remove(max_index)\n",
    "            copy_df = copy_df[~((copy_df['PatientID'] == ID) & (copy_df['Date'] == Date) & (\n",
    "                copy_df['MeasureDate'].isin(remove_date_list)))]\n",
    "\n",
    "        self.merge_df = copy_df\n",
    "\n",
    "        return self.merge_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e49916b3-657e-4afb-8aa3-9a53c9122ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon 데이터 전처리 시작\n",
      "폴더를 삭제하는 중 오류가 발생했습니다: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'C:\\\\Users\\\\howsr\\\\workspace\\\\1_DataPreprocessing\\\\basis\\\\region\\\\bucheon\\\\PreprocessData\\\\bucheon_medical.xlsx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:45: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path + '\\\\{}'.format(i), encoding='utf-16', index_col=0)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:45: DtypeWarning: Columns (8,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.dataDict[i] = pd.read_csv(self.path + '\\\\{}'.format(i), encoding='utf-16', index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are added\n",
      "이미 존재합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:292: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('Code', axis=1, inplace=True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df['MaxVital'] = MaxVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:294: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MaxVital_df.drop('VitalValue', axis=1, inplace=True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('Code', axis=1, inplace=True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('Code', axis=1, inplace=True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df['MinVital'] = MinVital_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df['Pulse'] = Pulse_df['VitalValue']\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:299: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  MinVital_df.drop('VitalValue', axis=1, inplace=True)\n",
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:300: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Pulse_df.drop('VitalValue', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86656, 70)\n",
      "   MedicalRecordID  PatientID  ScheduleID         ConsultTime  ConsultNote  \\\n",
      "0           876726          9     1126286 2022-11-23 10:55:00          NaN   \n",
      "1           942106          9     1195711 2023-02-16 09:45:00          NaN   \n",
      "2           943030          9     1196745 2023-02-17 10:25:00          NaN   \n",
      "3           956320          9     1210915 2023-03-07 19:20:00          NaN   \n",
      "4           956596          9     1211226 2023-03-08 09:25:00          NaN   \n",
      "\n",
      "                                        ProgressNote  Summary  RequestI  \\\n",
      "0  # 비만\\n\\n현재체중 : 65kg\\n마지막 약 복용일자 : 복용 중\\n포만감&식사...      NaN      25.0   \n",
      "1                                                NaN      NaN      24.0   \n",
      "2  # 비만\\n\\n현재체중 : 65kg\\n마지막 약 복용일자 : 복용 중\\n포만감&식사...      NaN       NaN   \n",
      "3                                                NaN      NaN       NaN   \n",
      "4                             # 비만\\n\\n>> 팻아웃플러스 9통        NaN       NaN   \n",
      "\n",
      "   RequestII  TreatmentCat  ...  Additional  Category1  Category2  Confirm  \\\n",
      "0        NaN             0  ...         NaN        0.0        0.0      0.0   \n",
      "1        NaN             0  ...         NaN        NaN        NaN      NaN   \n",
      "2        NaN             0  ...         NaN        0.0        0.0      0.0   \n",
      "3        NaN             0  ...         NaN        NaN        NaN      NaN   \n",
      "4        NaN             0  ...         NaN        0.0        0.0      0.0   \n",
      "\n",
      "   PrescMemo  PrescDeliverMemo  MedicationID_ORG  DoctorID_y  LicNo  \\\n",
      "0       None               NaN               NaN       491.0    NaN   \n",
      "1        NaN               NaN               NaN         NaN    NaN   \n",
      "2       None               NaN               NaN       996.0    NaN   \n",
      "3        NaN               NaN               NaN         NaN    NaN   \n",
      "4       None               NaN               NaN         0.0    NaN   \n",
      "\n",
      "   OrderyCheck  \n",
      "0          0.0  \n",
      "1          NaN  \n",
      "2          0.0  \n",
      "3          NaN  \n",
      "4          0.0  \n",
      "\n",
      "[5 rows x 70 columns]\n",
      "12863 ->        ReadingID  PatientID         MeasureDate  ObesityDegree   BCM   BMR  \\\n",
      "56        319441         50 2022-12-21 18:54:13            138  31.2  1391   \n",
      "57        325716         50 2023-02-15 19:14:12            137  30.1  1370   \n",
      "58        318431         68 2022-12-10 11:16:59            121  25.2  1214   \n",
      "59        318461         69 2022-12-10 11:39:59            142  45.0  1864   \n",
      "60        338666        128 2023-05-30 10:30:01            125  29.0  1344   \n",
      "...          ...        ...                 ...            ...   ...   ...   \n",
      "12858     381646     243081 2024-05-14 11:39:27            121  33.1  1493   \n",
      "12859     381786     243111 2024-05-14 18:53:57            115  25.5  1231   \n",
      "12860     381726     243135 2024-05-14 15:52:36            134  33.1  1474   \n",
      "12861     381736     243136 2024-05-14 16:08:10            135  24.6  1196   \n",
      "12862     381771     243141 2024-05-14 17:32:27            118  42.9  1776   \n",
      "\n",
      "        BMC  ReadingID_ORG  Weight  Height  ...  1000_LL   PBMF   PBF  PWHR  \\\n",
      "56     2.69            196    75.5   161.3  ...    199.0  291.2  37.4  0.91   \n",
      "57     2.64            196    75.0   161.3  ...    185.3  296.9  38.3  0.89   \n",
      "58     2.32            196    60.0   153.5  ...    214.6  228.5  34.9  0.88   \n",
      "59     3.94            196    96.1   175.6  ...    158.5  264.7  28.0  0.92   \n",
      "60     2.70            196    72.5   166.4  ...    204.0  260.9  37.8  0.90   \n",
      "...     ...            ...     ...     ...  ...      ...    ...   ...   ...   \n",
      "12858  3.20            196    80.4   178.1  ...    216.1  230.8  35.3  0.95   \n",
      "12859  2.51            196    64.3   163.0  ...    227.8  238.6  38.0  0.85   \n",
      "12860  2.92            196    75.8   164.4  ...    196.4  236.4  32.6  0.95   \n",
      "12861  2.32            196    66.6   153.2  ...    194.7  330.3  42.6  0.85   \n",
      "12862  3.77            196    83.6   179.7  ...    210.3  173.6  22.1  0.89   \n",
      "\n",
      "        PVFA   BMI   SMM  BodyFat    VFA   WHR  \n",
      "56     129.2  29.0  26.4     28.2  129.2  0.91  \n",
      "57     132.6  28.8  25.6     28.7  132.6  0.89  \n",
      "58     103.1  25.5  21.0     20.9  103.1  0.88  \n",
      "59     115.6  31.2  39.0     26.9  115.6  0.92  \n",
      "60     134.9  26.2  24.4     27.4  134.9  0.90  \n",
      "...      ...   ...   ...      ...    ...   ...  \n",
      "12858  141.2  25.3  28.2     28.4  141.2  0.95  \n",
      "12859  121.5  24.2  21.3     24.4  121.5  0.85  \n",
      "12860  116.7  28.0  28.2     24.7  116.7  0.95  \n",
      "12861  143.6  28.4  20.4     28.4  143.6  0.85  \n",
      "12862   77.5  25.9  37.1     18.5   77.5  0.89  \n",
      "\n",
      "[12807 rows x 186 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ZipFile.__del__ at 0x0000025A05E94360>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\howsr\\anaconda3\\Lib\\zipfile.py\", line 1874, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\howsr\\anaconda3\\Lib\\zipfile.py\", line 1891, in close\n",
      "    self.fp.seek(self.start_dir)\n",
      "ValueError: seek of closed file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon_inbody_df 저장완료\n",
      "bucheon_medical_df 저장완료\n",
      "bucheon_vital_df 저장완료\n",
      "bucheon_inbody_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:344: DtypeWarning: Columns (29,55,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.medical_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_medical.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon_medical_df 로드 완료\n",
      "bucheon_vital_df 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howsr\\AppData\\Local\\Temp\\ipykernel_31752\\2726661042.py:360: DtypeWarning: Columns (28,54,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.merge_df = pd.read_csv(f'{self.newPath}\\\\{self.region}_merge.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucheon_merge_df 로드 완료\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "'vital' 파일이 bucheon PreprocessData 디렉토리에 이미 존재합니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m region\u001b[38;5;241m.\u001b[39msaveDataFrame()\n\u001b[0;32m     19\u001b[0m region\u001b[38;5;241m.\u001b[39mloadPreprocessData()\n\u001b[1;32m---> 20\u001b[0m region\u001b[38;5;241m.\u001b[39mmakeMerge()\n\u001b[0;32m     21\u001b[0m region\u001b[38;5;241m.\u001b[39msaveMergeData()\n",
      "Cell \u001b[1;32mIn[18], line 370\u001b[0m, in \u001b[0;36mDataPreprocess.makeMerge\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    368\u001b[0m df_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mPreprocessData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merge.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(df_path):\n\u001b[1;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvital\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 파일이 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m PreprocessData 디렉토리에 이미 존재합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# 저장된 파일을 로드하지 않으면 timestamp error가 발생생\u001b[39;00m\n\u001b[0;32m    374\u001b[0m inbody_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbody_df\n",
      "\u001b[1;31mFileExistsError\u001b[0m: 'vital' 파일이 bucheon PreprocessData 디렉토리에 이미 존재합니다."
     ]
    }
   ],
   "source": [
    "region_list=[ 'bucheon', 'bundang', 'busan', 'hongdae', 'jamsil', 'gangnam','incheon']\n",
    "\n",
    "for region in region_list:\n",
    "    print(f'{region} 데이터 전처리 시작')\n",
    "    region = DataPreprocess(region = region)\n",
    "\n",
    "    region.delDir()\n",
    "    region.dataSet()\n",
    "    region.makeDir()\n",
    "\n",
    "    region.makeVital()\n",
    "    #print(region.vital_df.head())\n",
    "    region.makeMedical()\n",
    "    #print(region.medical_df.head())\n",
    "    region.makeInbody()\n",
    "    #print(region.inbody_df.head())\n",
    "    region.saveDataFrame()\n",
    "\n",
    "    region.loadPreprocessData()\n",
    "    region.makeMerge()\n",
    "    region.saveMergeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84980f1c-cb28-4843-9a96-fc6561a8c58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
